{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Cq2l0FUlvSVn",
      "metadata": {
        "id": "Cq2l0FUlvSVn"
      },
      "outputs": [],
      "source": [
        "!pip install patchify"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LkbhBn5DQGE_"
      },
      "id": "LkbhBn5DQGE_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"EOphtha_10k_Dataset.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"DataSet\")"
      ],
      "metadata": {
        "id": "_FbfoGPvPC8T"
      },
      "id": "_FbfoGPvPC8T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5c3ebbd",
      "metadata": {
        "id": "e5c3ebbd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from patchify import patchify\n",
        "from natsort import natsorted\n",
        "from patchify import unpatchify\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0de3894",
      "metadata": {
        "id": "f0de3894"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input, Dropout, Lambda, Add, Multiply, Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j50MPPxsLZ7e",
      "metadata": {
        "id": "j50MPPxsLZ7e"
      },
      "outputs": [],
      "source": [
        "# some hyper parameters\n",
        "epsilon = 0.10\n",
        "delta = 0.85\n",
        "lamda1 = 0.9\n",
        "lamda2 = 0.6\n",
        "gamma = 0.3\n",
        "initial_LR = 1e-3\n",
        "num_epochs = 150\n",
        "batch_size = 64\n",
        "\n",
        "patch_width = 48\n",
        "patch_height = 48\n",
        "patch_channels = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aFkAwLMTRHx-",
      "metadata": {
        "id": "aFkAwLMTRHx-"
      },
      "outputs": [],
      "source": [
        "# this function is for computing the 'average background luminance'\n",
        "\n",
        "def func_bg(inp, numFM):\n",
        "\n",
        "    def my_filter(shape, dtype=None):\n",
        "        kernel = np.zeros(shape)\n",
        "        f = [np.array([[1,1,1,1,1],[1,2,2,2,1],[1,2,0,2,1],[1,2,2,2,1],[1,1,1,1,1]])/32 for i in range(numFM)]\n",
        "        f = np.stack(f, axis=2)\n",
        "        kernel[:,:,numFM-1] = f\n",
        "        return kernel\n",
        "\n",
        "    out = Conv2D(filters=numFM, kernel_size=5, kernel_initializer=my_filter, strides=1, padding='same', trainable=False)(inp)\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe39l1EqRLRn",
      "metadata": {
        "id": "fe39l1EqRLRn"
      },
      "outputs": [],
      "source": [
        "# this function is for computing the 'maximal weighted average of gradients'\n",
        "\n",
        "def func_Gm(inp, numFM):\n",
        "\n",
        "    def G1(shape, dtype=None):\n",
        "        kernel = np.zeros(shape)\n",
        "        f = [np.array([[0,0,0,0,0],[1,3,8,3,1],[0,0,0,0,0],[-1,-3,-8,-3,-1],[0,0,0,0,0]])/16 for i in range(numFM)]\n",
        "        f = np.stack(f, axis=2)\n",
        "        kernel[:,:,numFM-1] = f\n",
        "        return kernel\n",
        "\n",
        "    def G2(shape, dtype=None):\n",
        "        kernel = np.zeros(shape)\n",
        "        f = [np.array([[0,0,1,0,0],[0,8,3,0,0],[1,3,0,-3,-1],[0,0,-3,-8,0],[0,0,-1,0,0]])/16 for i in range(numFM)]\n",
        "        f = np.stack(f, axis=2)\n",
        "        kernel[:,:,numFM-1] = f\n",
        "        return kernel\n",
        "\n",
        "    def G3(shape, dtype=None):\n",
        "        kernel = np.zeros(shape)\n",
        "        f = [np.array([[0,0,1,0,0],[0,0,3,8,0],[-1,-3,0,3,1],[0,-8,-3,0,0],[0,0,-1,0,0]])/16 for i in range(numFM)]\n",
        "        f = np.stack(f, axis=2)\n",
        "        kernel[:,:,numFM-1] = f\n",
        "        return kernel\n",
        "\n",
        "    def G4(shape, dtype=None):\n",
        "        kernel = np.zeros(shape)\n",
        "        f = [np.array([[0,1,0,-1,0],[0,3,0,-3,0],[0,8,0,-8,0],[0,3,0,-3,0],[0,1,0,-1,0]])/16 for i in range(numFM)]\n",
        "        f = np.stack(f, axis=2)\n",
        "        kernel[:,:,numFM-1] = f\n",
        "        return kernel\n",
        "\n",
        "    grad1 = Conv2D(filters=numFM, kernel_size=5, kernel_initializer=G1, strides=1, padding='same', trainable=False)(inp)\n",
        "    grad2 = Conv2D(filters=numFM, kernel_size=5, kernel_initializer=G2, strides=1, padding='same', trainable=False)(inp)\n",
        "    grad3 = Conv2D(filters=numFM, kernel_size=5, kernel_initializer=G3, strides=1, padding='same', trainable=False)(inp)\n",
        "    grad4 = Conv2D(filters=numFM, kernel_size=5, kernel_initializer=G4, strides=1, padding='same', trainable=False)(inp)\n",
        "\n",
        "    Gm = K.stack([grad1,grad2,grad3,grad4], axis=0)\n",
        "    Gm = K.max(K.abs(Gm), axis=0)\n",
        "\n",
        "    return Gm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FDBjUYbAEAGW",
      "metadata": {
        "id": "FDBjUYbAEAGW"
      },
      "outputs": [],
      "source": [
        "# this function is for calculating the pixel-domain JND values of input tensor\n",
        "\n",
        "def JND_pixel(inp, numFM):\n",
        "\n",
        "    bg = func_bg(inp, numFM) # average background luminance\n",
        "    Gm = func_Gm(inp, numFM) # maximal weighted average of gradients\n",
        "\n",
        "    # calculating luminance adaption threshold\n",
        "    T0 = 17.0;\n",
        "    Gamma = 3/128;\n",
        "    LA_t = tf.where(bg <= 127.0, (T0*(1.0-K.sqrt((bg/127.0)+K.epsilon()))+3.0), (Gamma*(bg-127.0)+3.0))\n",
        "\n",
        "    # calculating texture masking threshold\n",
        "    lamda = 0.5\n",
        "    alpha = 0.0001*bg + 0.115\n",
        "    beta = lamda - 0.01*bg\n",
        "    TM_t = Gm*alpha + beta\n",
        "\n",
        "    # calculating the final JND\n",
        "    T = K.stack([LA_t, TM_t], axis=0)\n",
        "    C_tg = 0.3\n",
        "    JND = LA_t + TM_t - C_tg*K.min(T, axis=0)\n",
        "\n",
        "    return JND"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this function is for scaling the attention values\n",
        "\n",
        "def func_norm(inp):\n",
        "\n",
        "    mini = K.min(inp, axis=[1,2], keepdims=True)\n",
        "    maxi = K.max(inp, axis=[1,2], keepdims=True)\n",
        "\n",
        "    out = (inp - mini) / ((maxi - mini) + K.epsilon())\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "lvirnQ90ibZo"
      },
      "id": "lvirnQ90ibZo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is JbAM\n",
        "\n",
        "def JbAM(inp, numFM):\n",
        "    # JND_pixel() function call\n",
        "    Attmap_WS = JND_pixel(inp, numFM)\n",
        "\n",
        "    # func_norm function call\n",
        "    Attmap_S = func_norm(Attmap_WS)\n",
        "\n",
        "    # multiplying the pixel-domain JND values with scaled attention values, to generate attention weighted tensor\n",
        "    out = Multiply()([inp, Attmap_S])\n",
        "    return out"
      ],
      "metadata": {
        "id": "Fer25N4bnzN6"
      },
      "id": "Fer25N4bnzN6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Iq9Iu0jcf25J",
      "metadata": {
        "id": "Iq9Iu0jcf25J"
      },
      "outputs": [],
      "source": [
        "# defining conv_block which is used multiple times in Encoder and Decoder\n",
        "\n",
        "def conv_block(inp, num_filters):\n",
        "\n",
        "    x = Conv2D(num_filters, (3,3), padding=\"same\")(inp)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, (3,3), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6036a2d",
      "metadata": {
        "id": "b6036a2d"
      },
      "outputs": [],
      "source": [
        "# defining the encoder block of Jb_UNet\n",
        "\n",
        "def encoder_block(inp, num_filters):\n",
        "\n",
        "    x = conv_block(inp, num_filters)\n",
        "    p = MaxPool2D((2,2))(x)\n",
        "\n",
        "    return x,p"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the decoder block of Jb_UNet\n",
        "\n",
        "def decoder_block(inp1, inp2, num_filters):\n",
        "\n",
        "    x = Conv2DTranspose(num_filters, (2,2), strides=2, padding=\"same\")(inp1)\n",
        "    skip_features = JbAM(inp2, num_filters)\n",
        "\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Conv2D(num_filters, (3,3), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "tKBAY3oRRBmx"
      },
      "id": "tKBAY3oRRBmx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e6db70d",
      "metadata": {
        "id": "5e6db70d"
      },
      "outputs": [],
      "source": [
        "# defining Jb_UNet\n",
        "def Jb_UNet(inp_shape):\n",
        "\n",
        "    inps = Input(inp_shape)\n",
        "    s = Lambda(lambda k:k/255)(inps)\n",
        "\n",
        "    c1, p1 = encoder_block(s, 32)\n",
        "    p1 = Dropout(0.2)(p1)\n",
        "    c2, p2 = encoder_block(p1, 64)\n",
        "    p2 = Dropout(0.2)(p2)\n",
        "    c3, p3 = encoder_block(p2, 128)\n",
        "    p3 = Dropout(0.2)(p3)\n",
        "    c4, p4 = encoder_block(p3, 256)\n",
        "    p4 = Dropout(0.2)(p4)\n",
        "\n",
        "    c5 = conv_block(p4, 512)\n",
        "\n",
        "    u6 = decoder_block(c5, c4, 256)\n",
        "    u7 = decoder_block(u6, c3, 128)\n",
        "    u8 = decoder_block(u7, c2, 64)\n",
        "    u9 = decoder_block(u8, c1, 32)\n",
        "\n",
        "    output = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(u9)\n",
        "\n",
        "    model = Model(inputs=[inps], outputs=[output], name=\"JbUNet\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining attention_aware BCE loss\n",
        "def bce_loss(y_true, y_pred):\n",
        "    term_0 = (1 - y_true) * K.log(1 - y_pred + K.epsilon())\n",
        "    term_1 = y_true * K.log(y_pred + K.epsilon())\n",
        "    loss = -K.mean(term_0 + term_1) # This is Binary Cross Entropy Loss\n",
        "    return loss\n",
        "\n",
        "# defining accuracy, sensitivity, specificity metrics\n",
        "def acc_met(y_true,y_pred):\n",
        "    out = K.mean(K.equal(y_true, y_pred))\n",
        "    return out\n",
        "\n",
        "def sensitivity(y_true,y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    neg_y_pred = 1 - y_pred_f\n",
        "    tp = K.sum(y_true_f * y_pred_f)\n",
        "    fn = K.sum(y_true_f * neg_y_pred)\n",
        "    return tp / (tp+fn+K.epsilon())\n",
        "\n",
        "def specificity(y_true,y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    neg_y_true = 1 - y_true_f\n",
        "    neg_y_pred = 1 - y_pred_f\n",
        "    fp = K.sum(neg_y_true * y_pred_f)\n",
        "    tn = K.sum(neg_y_true * neg_y_pred)\n",
        "    return tn / (tn+fp+K.epsilon())"
      ],
      "metadata": {
        "id": "7LszpXScr65s"
      },
      "id": "7LszpXScr65s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the Model\n",
        "\n",
        "opt = Adam(learning_rate = initial_LR)\n",
        "model = Jb_UNet((patch_width, patch_height, patch_channels))\n",
        "metrics_evaluated = [acc_met,\n",
        "                     sensitivity,\n",
        "                     specificity]\n",
        "model.compile(optimizer=opt, loss=bce_loss, metrics=metrics_evaluated)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Fv4r0VXRr7R3"
      },
      "id": "Fv4r0VXRr7R3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining a data generator\n",
        "\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, images, gts, batch_size=batch_size, shuffle=True):\n",
        "        super().__init__()\n",
        "        self.images = images\n",
        "        self.gts = gts\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.key_array = np.arange(self.images.shape[0], dtype=np.uint32)\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.key_array)//self.batch_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        keys = self.key_array[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        x = np.asarray(self.images[keys], dtype=np.float32)\n",
        "        y = np.asarray(self.gts[keys], dtype=np.float32)\n",
        "        return x, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            self.key_array = np.random.permutation(self.key_array)"
      ],
      "metadata": {
        "id": "0kb_9vWTr7W7"
      },
      "id": "0kb_9vWTr7W7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting the paths for images and ground truths\n",
        "\n",
        "datapath = \"/content/DataSet/EOphtha_Asitis_Dataset4/Images\"\n",
        "training_imgs = sorted(glob(os.path.join(datapath, \"Training_Set\", \"*jpg\")))\n",
        "\n",
        "datapath = \"/content/DataSet/EOphtha_Asitis_Dataset4/Ground_Truths\"\n",
        "training_maps = sorted(glob(os.path.join(datapath, \"Training_Set\", \"*png\")))"
      ],
      "metadata": {
        "id": "s30Ghp_b0UdV"
      },
      "id": "s30Ghp_b0UdV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reading the images\n",
        "\n",
        "length = len(training_imgs)\n",
        "train_X = np.zeros((length, patch_width, patch_height, patch_channels), dtype=np.uint8)\n",
        "\n",
        "for n in range(length):\n",
        "    image = cv2.imread(training_imgs[n], 0)\n",
        "\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    train_X[n] = image"
      ],
      "metadata": {
        "id": "g6gqd3za1KFl"
      },
      "id": "g6gqd3za1KFl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reading the corresponding ground truths\n",
        "\n",
        "length = len(training_maps)\n",
        "train_Y = np.zeros((length, patch_width, patch_height, patch_channels), dtype=float)\n",
        "\n",
        "for n in range(length):\n",
        "    seg_map = cv2.imread(training_maps[n], 0)\n",
        "\n",
        "    if np.max(seg_map)==0:\n",
        "        seg_map = seg_map\n",
        "    else:\n",
        "        seg_map = seg_map / np.max(seg_map)\n",
        "\n",
        "    seg_map = seg_map > 0.5\n",
        "    seg_map = np.expand_dims(seg_map, axis=-1)\n",
        "    train_Y[n] = seg_map"
      ],
      "metadata": {
        "id": "5mHQeFvT1a7h"
      },
      "id": "5mHQeFvT1a7h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = DataGenerator(images=train_X, gts=train_Y, batch_size=batch_size, shuffle=True)\n",
        "n_batches = len(generator)"
      ],
      "metadata": {
        "id": "nx52E-A7r7aT"
      },
      "id": "nx52E-A7r7aT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# these are to the loss, acc, sens, spec values during training\n",
        "loss_train = np.zeros(shape=(num_epochs,), dtype=float)\n",
        "acc_train  = np.zeros(shape=(num_epochs,), dtype=float)\n",
        "sens_train = np.zeros(shape=(num_epochs,), dtype=float)\n",
        "spec_train = np.zeros(shape=(num_epochs,), dtype=float)\n",
        "\n",
        "# training loop\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    epoch_loss_avg = tf.keras.metrics.Mean() # Keeping track of the training loss\n",
        "    epoch_acc_avg  = tf.keras.metrics.Mean() # Keeping track of the training accuracy\n",
        "    epoch_sens_avg = tf.keras.metrics.Mean() # Keeping track of the training sensitivity\n",
        "    epoch_spec_avg = tf.keras.metrics.Mean() # Keeping track of the training specificity\n",
        "\n",
        "    print('==== Epoch {}/{} ===='.format(epoch+1, num_epochs))\n",
        "\n",
        "    for batch in tqdm(range(n_batches)):\n",
        "\n",
        "        x, y = generator[batch]\n",
        "\n",
        "        with tf.GradientTape() as tape: # Forward pass\n",
        "            y_p = model(x, training=True)\n",
        "            loss = bce_loss(y_true=y, y_pred=y_p)\n",
        "\n",
        "        grad = tape.gradient(loss, model.trainable_variables) # Backpropagation\n",
        "        opt.apply_gradients(zip(grad, model.trainable_variables)) # Update network weights\n",
        "\n",
        "        epoch_loss_avg(loss)\n",
        "        y_pt = K.cast((y_p>0.5),float)\n",
        "        epoch_acc_avg(acc_met(y_true=y, y_pred=y_pt))\n",
        "        epoch_sens_avg(sensitivity(y_true=y, y_pred=y_pt))\n",
        "        epoch_spec_avg(specificity(y_true=y, y_pred=y_pt))\n",
        "\n",
        "    generator.on_epoch_end()\n",
        "\n",
        "    # Training Predictions\n",
        "    loss_train[epoch] = epoch_loss_avg.result()\n",
        "    acc_train[epoch] = epoch_acc_avg.result()\n",
        "    sens_train[epoch] = epoch_sens_avg.result()\n",
        "    spec_train[epoch] = epoch_spec_avg.result()\n",
        "\n",
        "    print(\"loss: {:.4f} - accuracy: {:.4f} - sensitivity: {:.4f} - specificity: {:.4f}\".format(loss_train[epoch], acc_train[epoch], sens_train[epoch], spec_train[epoch]))"
      ],
      "metadata": {
        "id": "qjnYsxEMr7iu"
      },
      "id": "qjnYsxEMr7iu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the Model\n",
        "model.save(\"JbUNet_EOphtha.h5\")"
      ],
      "metadata": {
        "id": "eb4IZW3JSErx"
      },
      "id": "eb4IZW3JSErx",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}