{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bf79568",
      "metadata": {
        "id": "8bf79568"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from natsort import natsorted\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, auc, f1_score, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f29ba65",
      "metadata": {
        "id": "8f29ba65"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input, Dropout, Lambda, Add, Multiply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9d8e925",
      "metadata": {
        "id": "c9d8e925"
      },
      "outputs": [],
      "source": [
        "# Patch dimension details\n",
        "Img_Width = 48\n",
        "Img_Height = 48\n",
        "Img_Channels = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f010d928",
      "metadata": {
        "id": "f010d928"
      },
      "outputs": [],
      "source": [
        "# Function for Sensitivity & Specificity\n",
        "\n",
        "def ce_loss(y_true, y_pred):\n",
        "    term_0 = (1 - y_true) * K.log(1 - y_pred + K.epsilon())\n",
        "    term_1 = y_true * K.log(y_pred + K.epsilon())\n",
        "    out = -K.mean(term_0 + term_1)                               # This is Binary Cross Entropy Loss\n",
        "    return out\n",
        "\n",
        "def acc_met(y_true,y_pred):\n",
        "    out = K.mean(K.equal(y_true, y_pred))\n",
        "    return out\n",
        "\n",
        "def sensitivity(y_true,y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    neg_y_pred = 1 - y_pred_f\n",
        "    tp = K.sum(y_true_f * y_pred_f)\n",
        "    fn = K.sum(y_true_f * neg_y_pred)\n",
        "    return tp / (tp+fn+K.epsilon())\n",
        "\n",
        "def specificity(y_true,y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    neg_y_true = 1 - y_true_f\n",
        "    neg_y_pred = 1 - y_pred_f\n",
        "    fp = K.sum(neg_y_true * y_pred_f)\n",
        "    tn = K.sum(neg_y_true * neg_y_pred)\n",
        "    return tn / (tn + fp + K.epsilon())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e12cd41",
      "metadata": {
        "id": "7e12cd41"
      },
      "outputs": [],
      "source": [
        "# Loading the model ..\n",
        "seg_model = load_model(\"/content/UNet_JND_EOphtha.h5\", custom_objects={\"ce_loss\":ce_loss, \"acc_met\":acc_met, \"sensitivity\": sensitivity, \"specificity\": specificity})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f2244e0",
      "metadata": {
        "id": "0f2244e0"
      },
      "outputs": [],
      "source": [
        "######################### Testing the model for single image #########################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73ee1d17",
      "metadata": {
        "id": "73ee1d17"
      },
      "outputs": [],
      "source": [
        "# Loading the image and applying CLAHE\n",
        "\n",
        "img = cv2.imread('EOphtha_43.jpg')\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# The initial processing of the image\n",
        "img_g = img[:,:,1]\n",
        "\n",
        "# Applying CLAHE as pre-processing step\n",
        "clahe = cv2.createCLAHE(clipLimit = 8, tileGridSize=(8,8))\n",
        "img_c = clahe.apply(img_g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6c39e50",
      "metadata": {
        "id": "e6c39e50"
      },
      "outputs": [],
      "source": [
        "# loading the ground truth\n",
        "\n",
        "[m,n] = img_c.shape\n",
        "\n",
        "gt = cv2.imread('EOphtha_47.png',0)\n",
        "gt = gt / 255.0\n",
        "gt = (gt > 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "031361cd",
      "metadata": {
        "id": "031361cd"
      },
      "outputs": [],
      "source": [
        "tot = 0\n",
        "step = 8\n",
        "for i in range(0,m,step):\n",
        "    for j in range(0,n,step):\n",
        "        if((i+48)>(m-1) or (j+48)>(n-1)):\n",
        "            pass\n",
        "        else:\n",
        "            tot = tot + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd67d5f1",
      "metadata": {
        "id": "dd67d5f1"
      },
      "outputs": [],
      "source": [
        "threshold = 0.30 # change this to high value if false positives are coming\n",
        "cnt1 = 0\n",
        "cnt2 = 0\n",
        "iarr = []\n",
        "jarr = []\n",
        "patches_gat = np.zeros((tot,48,48,1))\n",
        "final_res = np.zeros((m,n))\n",
        "\n",
        "for i in range(0,m,step):\n",
        "    for j in range(0,n,step):\n",
        "        if((i+48)>(m-1) or (j+48)>(n-1)):\n",
        "            pass\n",
        "        else:\n",
        "            patch_img = img_c[i:i+48,j:j+48]\n",
        "            patch_img = np.expand_dims(patch_img, axis=-1)\n",
        "            patch_img = np.expand_dims(patch_img, axis=0)\n",
        "            patches_gat[cnt1] = patch_img\n",
        "            cnt1 = cnt1 + 1\n",
        "            iarr.append(i)\n",
        "            jarr.append(j)\n",
        "\n",
        "inter_res = seg_model.predict(patches_gat,verbose=False)\n",
        "inter_res = (inter_res > threshold)\n",
        "for k in range(cnt1):\n",
        "    final_res[iarr[k]:(iarr[k]+48),jarr[k]:(jarr[k]+48)] = final_res[iarr[k]:iarr[k]+48,jarr[k]:jarr[k]+48] + np.squeeze(inter_res[cnt2])\n",
        "    cnt2 = cnt2 + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "476dc868",
      "metadata": {
        "id": "476dc868"
      },
      "outputs": [],
      "source": [
        "psm_th2 = final_res / np.max(final_res)\n",
        "psm_th2 = (psm_th2 > 0.05).astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9faa94c8",
      "metadata": {
        "id": "9faa94c8"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "fig.set_size_inches(25,25)\n",
        "\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax1.imshow(img_c, cmap='gray')\n",
        "ax1.set_title(\"Input Fundus Image\")\n",
        "ax1.axis(False)\n",
        "ax1.grid(False)\n",
        "\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.imshow(psm_th2, cmap=\"gray\")\n",
        "ax2.set_title(\"Predicted Segmented Map\")\n",
        "ax2.axis(False)\n",
        "ax2.grid(False)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}