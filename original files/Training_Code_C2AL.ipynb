{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "oYPW4Vj7vPUg",
      "metadata": {
        "id": "oYPW4Vj7vPUg"
      },
      "outputs": [],
      "source": [
        "# # Mounting the Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "hk-Hm5XrvQCR",
      "metadata": {
        "id": "hk-Hm5XrvQCR"
      },
      "outputs": [],
      "source": [
        "# import zipfile\n",
        "# with zipfile.ZipFile(\"EOphtha_10k_Dataset.zip\",\"r\") as zip_ref:\n",
        "#     zip_ref.extractall(\"DataSet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "Cq2l0FUlvSVn",
      "metadata": {
        "id": "Cq2l0FUlvSVn"
      },
      "outputs": [],
      "source": [
        "# !pip install patchify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e5c3ebbd",
      "metadata": {
        "id": "e5c3ebbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "# from patchify import patchify\n",
        "from natsort import natsorted\n",
        "# from patchify import unpatchify\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f0de3894",
      "metadata": {
        "id": "f0de3894"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input, Dropout, Lambda, Add, Multiply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fef66bb4",
      "metadata": {
        "id": "fef66bb4"
      },
      "outputs": [],
      "source": [
        "def simAM(inp1, inp2):\n",
        "\n",
        "    lamda = 1e-4\n",
        "    d = K.square(inp1 - K.mean(inp1, axis=[1,2], keepdims=True))\n",
        "    n = (inp1.shape[1] * inp1.shape[2]) - 1\n",
        "    v = K.sum(d, axis=[1,2], keepdims=True) / n\n",
        "    td_weights = (d / (4*(v + lamda))) + 0.5\n",
        "    td_weights = Activation('sigmoid')(td_weights)\n",
        "    out = Multiply()([inp2, td_weights])\n",
        "\n",
        "    return out, td_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "Iq9Iu0jcf25J",
      "metadata": {
        "id": "Iq9Iu0jcf25J"
      },
      "outputs": [],
      "source": [
        "# A Convolutional Block is composed of 2 consecutive (conv + BN + relu) operations, with a BN in between.\n",
        "\n",
        "def conv_block(inp, num_filters):\n",
        "\n",
        "    x = Conv2D(num_filters, (3,3), padding=\"same\")(inp)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, (3,3), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b6036a2d",
      "metadata": {
        "id": "b6036a2d"
      },
      "outputs": [],
      "source": [
        "# A Encoder Block is combination of conv_block & max pooling operation.\n",
        "\n",
        "def encoder_block(inp, num_filters):\n",
        "\n",
        "    x = conv_block(inp, num_filters)\n",
        "    p = MaxPool2D((2,2))(x)\n",
        "\n",
        "    return x,p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5340d755",
      "metadata": {
        "id": "5340d755"
      },
      "outputs": [],
      "source": [
        "# Defining Decoder Block\n",
        "def decoder_block(inp1, inp2, num_filters):\n",
        "\n",
        "    x = Conv2DTranspose(num_filters, (2,2), strides=2, padding=\"same\")(inp1)\n",
        "    skip_features, d3_weights = simAM(x, inp2)\n",
        "\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Conv2D(num_filters, (3,3), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x, d3_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5e6db70d",
      "metadata": {
        "id": "5e6db70d"
      },
      "outputs": [],
      "source": [
        "def build_UNet(inp1_shape,inp2_shape):\n",
        "\n",
        "    inps1 = Input(inp1_shape)\n",
        "    inps2 = Input(inp2_shape)\n",
        "\n",
        "    s = Lambda(lambda k:k/255)(inps1)\n",
        "    c1, p1 = encoder_block(s, 32)\n",
        "    p1 = Dropout(0.2)(p1)\n",
        "    c2, p2 = encoder_block(p1, 64)\n",
        "    p2 = Dropout(0.2)(p2)\n",
        "    c3, p3 = encoder_block(p2, 128)\n",
        "    p3 = Dropout(0.2)(p3)\n",
        "    c4, p4 = encoder_block(p3, 256)\n",
        "    p4 = Dropout(0.2)(p4)\n",
        "\n",
        "    c5 = conv_block(p4, 512)\n",
        "\n",
        "    u6, d34_weights = decoder_block(c5, c4, 256)\n",
        "    u7, d33_weights = decoder_block(u6, c3, 128)\n",
        "    u8, d32_weights = decoder_block(u7, c2, 64)\n",
        "    u9, d31_weights = decoder_block(u8, c1, 32)\n",
        "\n",
        "    output1 = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(u9)\n",
        "    output2 = K.min((K.sum((inps2 * K.square(d31_weights)), axis=[1,2]) / (K.sum(inps2, axis=[1,2]) + K.epsilon())),axis=[1])\n",
        "\n",
        "    model = Model(inputs=[inps1,inps2], outputs=[output1,output2], name=\"UNet\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "432ca22e",
      "metadata": {
        "id": "432ca22e"
      },
      "outputs": [],
      "source": [
        "# Here, Images Details are to be Included\n",
        "Img_Width = 48\n",
        "Img_Height = 48\n",
        "Img_Channels = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "a350821b",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = build_UNet((Img_Width, Img_Height, Img_Channels),(Img_Width, Img_Height, Img_Channels))\n",
        "model2 = tf.keras.models.clone_model(model)\n",
        "# model.load_weights('UNet_JND_EOphtha.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "57e5ef28",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 470ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[array([[[[0.5],\n",
              "          [0.5],\n",
              "          [0.5],\n",
              "          ...,\n",
              "          [0.5],\n",
              "          [0.5],\n",
              "          [0.5]],\n",
              " \n",
              "         [[0.5],\n",
              "          [0.5],\n",
              "          [0.5],\n",
              "          ...,\n",
              "          [0.5],\n",
              "          [0.5],\n",
              "          [0.5]],\n",
              " \n",
              "         [[0.5],\n",
              "          [0.5],\n",
              "          [0.5],\n",
              "          ...,\n",
              "          [0.5],\n",
              "          [0.5],\n",
              "          [0.5]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[0.5],\n",
              "          [0.5],\n",
              "          [0.5],\n",
              "          ...,\n",
              "          [0.5],\n",
              "          [0.5],\n",
              "          [0.5]],\n",
              " \n",
              "         [[0.5],\n",
              "          [0.5],\n",
              "          [0.5],\n",
              "          ...,\n",
              "          [0.5],\n",
              "          [0.5],\n",
              "          [0.5]],\n",
              " \n",
              "         [[0.5],\n",
              "          [0.5],\n",
              "          [0.5],\n",
              "          ...,\n",
              "          [0.5],\n",
              "          [0.5],\n",
              "          [0.5]]]], dtype=float32),\n",
              " array([0.], dtype=float32)]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict([tf.zeros([1,48,48,1]), tf.zeros([1,48,48,1])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6e9dfce",
      "metadata": {
        "id": "a6e9dfce"
      },
      "outputs": [],
      "source": [
        "# Reading the Training & Testing Images from Google Drive ..\n",
        "\n",
        "datapath = \"EOphtha_2L_Dataset\\Images\"\n",
        "Training_imgs = sorted(glob(os.path.join(datapath, \"Training_Set\", \"*jpg\")))\n",
        "\n",
        "datapath = \"EOphtha_2L_Dataset\\Ground_Truths\"\n",
        "Training_maps = sorted(glob(os.path.join(datapath, \"Training_Set\", \"*png\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b94b627",
      "metadata": {
        "id": "9b94b627"
      },
      "outputs": [],
      "source": [
        "# Random Shuffling of Images & Maps Accordingly\n",
        "c = list(zip(Training_imgs, Training_maps))\n",
        "random.shuffle(c)\n",
        "Training_imgs, Training_maps = zip(*c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0113f3cb",
      "metadata": {
        "id": "0113f3cb"
      },
      "outputs": [],
      "source": [
        "# Just for Checking ..\n",
        "print(len(Training_imgs))\n",
        "print(len(Training_maps))\n",
        "\n",
        "num = random.randint(0, len(Training_imgs))\n",
        "print(Training_imgs[num])\n",
        "print(Training_maps[num])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pbp2AKzxFTh8",
      "metadata": {
        "id": "pbp2AKzxFTh8"
      },
      "outputs": [],
      "source": [
        "# Making Training Images ready ..\n",
        "\n",
        "length = len(Training_imgs)\n",
        "train_X = np.zeros((length, Img_Width, Img_Height, Img_Channels), dtype=np.uint8)\n",
        "\n",
        "for n in range(length):\n",
        "    image = cv2.imread(Training_imgs[n], 0)\n",
        "\n",
        "    image = np.expand_dims(image, axis=-1)\n",
        "    train_X[n] = image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WFM-wgMvFUJi",
      "metadata": {
        "id": "WFM-wgMvFUJi"
      },
      "outputs": [],
      "source": [
        "# Making Segmentation Map (Ground Truth) for the Training Images ready ..\n",
        "\n",
        "length = len(Training_maps)\n",
        "train_Y = np.zeros((length, Img_Width, Img_Height, Img_Channels), dtype=float)\n",
        "\n",
        "for n in range(length):\n",
        "    seg_map = cv2.imread(Training_maps[n], 0)\n",
        "\n",
        "    if np.max(seg_map)==0:\n",
        "        seg_map = seg_map\n",
        "    else:\n",
        "        seg_map = seg_map / 255.0\n",
        "\n",
        "    seg_map = seg_map > 0.5\n",
        "    seg_map = np.expand_dims(seg_map, axis=-1)\n",
        "    train_Y[n] = seg_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1_qbO0CloRnY",
      "metadata": {
        "id": "1_qbO0CloRnY"
      },
      "outputs": [],
      "source": [
        "# Seperating Training and Validation Datasets\n",
        "train_X, val_X, train_Y, val_Y = train_test_split(train_X, train_Y, test_size=0.20, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3v0Kn0eTCXfA",
      "metadata": {
        "id": "3v0Kn0eTCXfA"
      },
      "outputs": [],
      "source": [
        "# Printing the Info ..\n",
        "print('Training Set Details')\n",
        "print(train_X.shape)\n",
        "print(train_Y.shape)\n",
        "print('Validation Set Details')\n",
        "print(val_X.shape)\n",
        "print(val_Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bF2ap93be2Sg",
      "metadata": {
        "id": "bF2ap93be2Sg"
      },
      "outputs": [],
      "source": [
        "print(\"Unique Values of Training Masks are \", np.unique(train_Y))\n",
        "print(\"Unique Values of Validation Masks are \", np.unique(val_Y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a80668a0",
      "metadata": {
        "id": "a80668a0"
      },
      "outputs": [],
      "source": [
        "# Counting MA and nonMA images in training dataset\n",
        "var0 = 0\n",
        "var1 = 0\n",
        "for i in range(len(train_Y)):\n",
        "    img = train_Y[i]\n",
        "    img = np.squeeze(img)\n",
        "    if(np.max(img) != 0):\n",
        "        var1 = var1 + 1\n",
        "    else:\n",
        "        var0 = var0 + 1\n",
        "print(\"Train MA Images - {}\".format(var1))\n",
        "print(\"Train nonMA Images - {}\".format(var0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oRwNJcl8yOHb",
      "metadata": {
        "id": "oRwNJcl8yOHb"
      },
      "outputs": [],
      "source": [
        "# Counting MA and nonMA images in valiation dataset\n",
        "var0 = 0\n",
        "var1 = 0\n",
        "for i in range(len(val_Y)):\n",
        "    img = val_Y[i]\n",
        "    img = np.squeeze(img)\n",
        "    if(np.max(img) != 0):\n",
        "        var1 = var1 + 1\n",
        "    else:\n",
        "        var0 = var0 + 1\n",
        "print(\"Val MA Images - {}\".format(var1))\n",
        "print(\"Val nonMA Images - {}\".format(var0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea19c666",
      "metadata": {
        "id": "ea19c666"
      },
      "outputs": [],
      "source": [
        "# (For Training DataSet) --> Displaying Fundus Image and its Ground Truth (Segmentation Map)\n",
        "\n",
        "num = random.randint(0, len(train_X))   # Random Number\n",
        "# Printing the size of Image\n",
        "print(train_X[num].shape)\n",
        "fundus_img = train_X[num]\n",
        "\n",
        "# Printing the size of Mask\n",
        "print(train_Y[num].shape)\n",
        "img_mask = train_Y[num]\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "ax1.imshow(np.squeeze(fundus_img), cmap=\"gray\")\n",
        "ax1.grid(False)\n",
        "ax2.imshow(np.squeeze(img_mask), cmap=\"gray\")\n",
        "ax2.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m9iUAxUspptI",
      "metadata": {
        "id": "m9iUAxUspptI"
      },
      "outputs": [],
      "source": [
        "# (For Validation DataSet) --> Displaying Fundus Image and its Ground Truth (Segmentation Map)\n",
        "\n",
        "num = random.randint(0, len(val_X))   # Random Number\n",
        "# Printing the size of Image\n",
        "print(val_X[num].shape)\n",
        "fundus_img = val_X[num]\n",
        "\n",
        "# Printing the size of Mask\n",
        "print(val_Y[num].shape)\n",
        "img_mask = val_Y[num]\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "ax1.imshow(np.squeeze(fundus_img), cmap=\"gray\")\n",
        "ax1.grid(False)\n",
        "ax2.imshow(np.squeeze(img_mask), cmap=\"gray\")\n",
        "ax2.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZlCEzGT5_hg4",
      "metadata": {
        "id": "ZlCEzGT5_hg4"
      },
      "outputs": [],
      "source": [
        "# some parameters initializing ..\n",
        "initial_LR = 1e-3\n",
        "num_epochs = 150\n",
        "wdecay = (initial_LR / num_epochs)\n",
        "bs = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JSmMuYGUVCrG",
      "metadata": {
        "id": "JSmMuYGUVCrG"
      },
      "outputs": [],
      "source": [
        "# Function for Sensitivity & Specificity\n",
        "\n",
        "def ce_loss(y_true, y_pred, maxis):\n",
        "    term_0 = (1 - y_true) * K.log(1 - y_pred + K.epsilon())\n",
        "    term_1 = y_true * K.log(y_pred + K.epsilon())\n",
        "\n",
        "    ## Calculating ATT loss .. due to MA Part\n",
        "    cnt = K.sum(K.cast(K.equal(maxis, 0), float))\n",
        "    att_loss1 = K.sum(1 - maxis) - cnt\n",
        "\n",
        "    bce_loss = -K.mean(term_0 + term_1)                               # This is Binary Cross Entropy Loss\n",
        "    att_loss = (att_loss1 / bs)  # This is Attention Deviation Loss ('This loss concentrates on NonMA Regions')\n",
        "    out = ((att_loss*att_loss) + (bce_loss*bce_loss)) / (att_loss + bce_loss)  # Total Loss is Contra Harmonic Mean of BCE_Loss & Attention Loss\n",
        "    return out, bce_loss, att_loss\n",
        "\n",
        "def acc_met(y_true,y_pred):\n",
        "    out = K.mean(K.equal(y_true, y_pred))\n",
        "    return out\n",
        "\n",
        "def sensitivity(y_true,y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    neg_y_pred = 1 - y_pred_f\n",
        "    tp = K.sum(y_true_f * y_pred_f)\n",
        "    fn = K.sum(y_true_f * neg_y_pred)\n",
        "    return tp / (tp+fn+K.epsilon())\n",
        "\n",
        "def specificity(y_true,y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    neg_y_true = 1 - y_true_f\n",
        "    neg_y_pred = 1 - y_pred_f\n",
        "    fp = K.sum(neg_y_true * y_pred_f)\n",
        "    tn = K.sum(neg_y_true * neg_y_pred)\n",
        "    return tn / (tn + fp + K.epsilon())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30efe65d",
      "metadata": {
        "id": "30efe65d"
      },
      "outputs": [],
      "source": [
        "# Compiling the Model ..\n",
        "\n",
        "opt = Adam(learning_rate = initial_LR, decay=wdecay)\n",
        "model = build_UNet((Img_Width, Img_Height, Img_Channels),(Img_Width, Img_Height, Img_Channels))\n",
        "metrics_evaluated = [acc_met,\n",
        "                     sensitivity,\n",
        "                     specificity]\n",
        "model.compile(optimizer=opt, loss=ce_loss, metrics=metrics_evaluated)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ipsYJyOB_n4I",
      "metadata": {
        "id": "ipsYJyOB_n4I"
      },
      "outputs": [],
      "source": [
        "####################################### CUSTOM TRAINING #########################################\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, images, labels, batch_size=bs, shuffle=True):\n",
        "        super().__init__()\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.key_array = np.arange(self.images.shape[0], dtype=np.uint32)\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.key_array)//self.batch_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        keys = self.key_array[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        x = np.asarray(self.images[keys], dtype=np.float32)\n",
        "        y = np.asarray(self.labels[keys], dtype=np.float32)\n",
        "        return x, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            self.key_array = np.random.permutation(self.key_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7uyhvELZ_n9S",
      "metadata": {
        "id": "7uyhvELZ_n9S"
      },
      "outputs": [],
      "source": [
        "generator = DataGenerator(images=train_X, labels=train_Y, batch_size=bs, shuffle=True)\n",
        "n_batches = len(generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jLIPjWD2_oAk",
      "metadata": {
        "id": "jLIPjWD2_oAk"
      },
      "outputs": [],
      "source": [
        "# Initializing the variables\n",
        "\n",
        "bceloss_train = np.zeros(shape=(num_epochs,), dtype=float)\n",
        "attloss_train = np.zeros(shape=(num_epochs,), dtype=float)\n",
        "totalloss_train = np.zeros(shape=(num_epochs,), dtype=float)\n",
        "acc_train  = np.zeros(shape=(num_epochs,), dtype=float)\n",
        "sens_train = np.zeros(shape=(num_epochs,), dtype=float)\n",
        "spec_train = np.zeros(shape=(num_epochs,), dtype=float)\n",
        "\n",
        "loss_val = np.zeros(shape=(num_epochs,), dtype=float)\n",
        "acc_val  = np.zeros(shape=(num_epochs,), dtype=float)\n",
        "sens_val = np.zeros(shape=(num_epochs,), dtype=float)\n",
        "spec_val = np.zeros(shape=(num_epochs,), dtype=float)\n",
        "\n",
        "threshold = 0.50 # Defining the Threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "n2w7htjH_oDk",
      "metadata": {
        "id": "n2w7htjH_oDk"
      },
      "outputs": [],
      "source": [
        "for epoch in range(num_epochs):\n",
        "\n",
        "    epoch_bceloss_avg = tf.keras.metrics.Mean() # Keeping track of the training loss\n",
        "    epoch_attloss_avg = tf.keras.metrics.Mean() # Keeping track of the training loss\n",
        "    epoch_totalloss_avg = tf.keras.metrics.Mean() # Keeping track of the training loss\n",
        "    epoch_acc_avg  = tf.keras.metrics.Mean() # Keeping track of the training accuracy\n",
        "    epoch_sens_avg = tf.keras.metrics.Mean() # Keeping track of the training sensitivity\n",
        "    epoch_spec_avg = tf.keras.metrics.Mean() # Keeping track of the training specificity\n",
        "\n",
        "    print('==== Epoch {}/{} ===='.format(epoch+1, num_epochs))\n",
        "\n",
        "    for batch in tqdm(range(n_batches)):\n",
        "\n",
        "        x, y = generator[batch]\n",
        "\n",
        "        with tf.GradientTape() as tape: # Forward pass\n",
        "            y_p, maxi = model([x, y], training=True)\n",
        "            loss, bce_loss, att_loss = ce_loss(y_true=y, y_pred=y_p, maxis=maxi)\n",
        "\n",
        "        grad = tape.gradient(loss, model.trainable_variables) # Backpropagation\n",
        "        opt.apply_gradients(zip(grad, model.trainable_variables)) # Update network weights\n",
        "\n",
        "        epoch_bceloss_avg(bce_loss)\n",
        "        epoch_attloss_avg(att_loss)\n",
        "        epoch_totalloss_avg(loss)\n",
        "        y_pt = K.cast((y_p>threshold),float)\n",
        "        epoch_acc_avg(acc_met(y_true=y, y_pred=y_pt))\n",
        "        epoch_sens_avg(sensitivity(y_true=y, y_pred=y_pt))\n",
        "        epoch_spec_avg(specificity(y_true=y, y_pred=y_pt))\n",
        "\n",
        "    generator.on_epoch_end()\n",
        "\n",
        "    # Training Predictions\n",
        "    bceloss_train[epoch] = epoch_bceloss_avg.result()\n",
        "    attloss_train[epoch] = epoch_attloss_avg.result()\n",
        "    totalloss_train[epoch] = epoch_totalloss_avg.result()\n",
        "    acc_train[epoch] = epoch_acc_avg.result()\n",
        "    sens_train[epoch] = epoch_sens_avg.result()\n",
        "    spec_train[epoch] = epoch_spec_avg.result()\n",
        "\n",
        "    # Validation predictions\n",
        "    y_p, maxi  = model.predict([val_X, val_Y], verbose=False)\n",
        "\n",
        "    loss_val[epoch],_,_ = ce_loss(y_true=val_Y, y_pred=y_p, maxis=maxi)\n",
        "    y_pt = K.cast((y_p>threshold),\"double\")\n",
        "    acc_val[epoch] = acc_met(y_true=val_Y, y_pred=y_pt)\n",
        "    sens_val[epoch] = sensitivity(y_true=val_Y, y_pred=y_pt)\n",
        "    spec_val[epoch] = specificity(y_true=val_Y, y_pred=y_pt)\n",
        "\n",
        "    print(\"bce_loss: {:.4f} - att_loss: {:.4f} - total_loss: {:.4f} - accuracy: {:.4f} - sensitivity: {:.4f} - specificity: {:.4f} - val_loss: {:.4f} - val_accuracy: {:.4f} - val_sensitivity: {:.4f} - val_specificity: {:.4f}\".format(bceloss_train[epoch], attloss_train[epoch], totalloss_train[epoch], acc_train[epoch], sens_train[epoch], spec_train[epoch], loss_val[epoch], acc_val[epoch], sens_val[epoch], spec_val[epoch]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JERE7gpmB8C8",
      "metadata": {
        "id": "JERE7gpmB8C8"
      },
      "outputs": [],
      "source": [
        "# plotting Training, Validation - Accuracy, Loss, Sensitivity, Specificity, AUC\n",
        "N = num_epochs\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1,4, figsize=(18, 5))\n",
        "\n",
        "ax1.plot(np.arange(0,N), acc_val, label = \"val_acc\")\n",
        "ax1.plot(np.arange(0,N), acc_train, label = \"train_acc\")\n",
        "ax1.set_title(\"Train & Val Accuracy\")\n",
        "ax1.set(xlabel = \"Epoch Number\", ylabel = \"Accuracy\")\n",
        "ax1.legend(loc = \"lower right\")\n",
        "\n",
        "ax2.plot(np.arange(0,N), loss_val, label = \"val_loss\")\n",
        "ax2.plot(np.arange(0,N), totalloss_train, label = \"train_loss\")\n",
        "ax2.set_title(\"Train & Val Loss\")\n",
        "ax2.set(xlabel = \"Epoch Number\", ylabel = \"Loss\")\n",
        "ax2.legend(loc = \"upper right\")\n",
        "\n",
        "ax3.plot(np.arange(0,N), sens_val, label = \"val_sensitivity\")\n",
        "ax3.plot(np.arange(0,N), sens_train, label = \"train_sensitivity\")\n",
        "ax3.set_title(\"Train & Val Sensitivity\")\n",
        "ax3.set(xlabel = \"Epoch Number\", ylabel = \"Sensitivity\")\n",
        "ax3.legend(loc = \"lower right\")\n",
        "\n",
        "ax4.plot(np.arange(0,N), spec_val, label = \"val_specificity\")\n",
        "ax4.plot(np.arange(0,N), spec_train, label = \"train_specificity\")\n",
        "ax4.set_title(\"Train & Val Specificity\")\n",
        "ax4.set(xlabel = \"Epoch Number\", ylabel = \"Specificity\")\n",
        "ax4.legend(loc = \"lower right\")\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.savefig(\"Metrics_Plot.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4kR0mWLd0Fss",
      "metadata": {
        "id": "4kR0mWLd0Fss"
      },
      "outputs": [],
      "source": [
        "# Saving the Model\n",
        "model.save(\"UNet_EOphtha_simAM_Attloss_T1.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q-X_EGM10REI",
      "metadata": {
        "id": "Q-X_EGM10REI"
      },
      "outputs": [],
      "source": [
        "########################################################### END OF THE CODE ###########################################################"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
